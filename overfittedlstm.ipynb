{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9149877,"sourceType":"datasetVersion","datasetId":5526909}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/rubinr12/overfittedlstm-ipynb?scriptVersionId=192164559\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import precision_score, recall_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, GRU, Bidirectional, Input\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom torch.nn.utils import clip_grad_norm_\nfrom torch.optim import RMSprop","metadata":{"execution":{"iopub.status.busy":"2024-08-11T13:02:05.517807Z","iopub.execute_input":"2024-08-11T13:02:05.518874Z","iopub.status.idle":"2024-08-11T13:02:05.529405Z","shell.execute_reply.started":"2024-08-11T13:02:05.518831Z","shell.execute_reply":"2024-08-11T13:02:05.52836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load data\ntrain_data = pd.read_excel('/kaggle/input/dataset/train.xlsx')\ntest_data = pd.read_csv('/kaggle/input/dataset/test.csv')\n\n# Drop unnecessary columns\ntrain_data.drop(['job_id'], axis=1, inplace=True)\ntest_data.drop(columns=['job_id','Latitude', 'Longitude'], inplace=True)\n\n# Separate features and labels\ntrain_labels = train_data['label'].values\ntrain_features = train_data.drop(['label'], axis=1).values\n\ntest_labels = test_data['label'].values\ntest_features = test_data.drop(['label'], axis=1).values\n\n# Normalize/Standardize the features\nscaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_features)\ntest_features = scaler.transform(test_features)\n\n# Create sliding windows\ndef create_sliding_window(data, labels, window_size=20):\n    X = []\n    y = []\n    for i in range(len(data) - window_size):\n        X.append(data[i:i+window_size])\n        y.append(labels[i+window_size-1])\n    return np.array(X), np.array(y)\n\nX_train, y_train = create_sliding_window(train_features, train_labels, window_size=20)\nX_test, y_test = create_sliding_window(test_features, test_labels, window_size=20)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T11:20:28.098493Z","iopub.execute_input":"2024-08-11T11:20:28.099172Z","iopub.status.idle":"2024-08-11T11:20:28.513852Z","shell.execute_reply.started":"2024-08-11T11:20:28.099141Z","shell.execute_reply":"2024-08-11T11:20:28.513094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Build LSTM model with Dropout and Regularization\n# model = Sequential()\n# model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False, kernel_regularizer='l2'))\n# model.add(Dropout(0.4))\n# model.add(Dense(1, activation='sigmoid'))\n\n# # Compile the model\n# model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# # Early stopping callback\n# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# # Train the model with early stopping and class weights\n# model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping], class_weight=class_weight_dict)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:40:55.624521Z","iopub.execute_input":"2024-08-11T09:40:55.625339Z","iopub.status.idle":"2024-08-11T09:41:44.958667Z","shell.execute_reply.started":"2024-08-11T09:40:55.6253Z","shell.execute_reply":"2024-08-11T09:41:44.957725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Build LSTM model\n# model = Sequential()\n# model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n# model.add(Dense(1, activation='sigmoid'))\n# model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n\n# # Train the model\n# model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Compute class weights to handle class imbalance\n# class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n# class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n\n\n# model = Sequential()\n# model.add(LSTM(32, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False, kernel_regularizer='l2'))\n# model.add(BatchNormalization())\n# model.add(Dropout(0.5))  \n# model.add(Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping], class_weight=class_weight_dict)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T09:48:24.853022Z","iopub.execute_input":"2024-08-11T09:48:24.853381Z","iopub.status.idle":"2024-08-11T09:50:42.900093Z","shell.execute_reply.started":"2024-08-11T09:48:24.853351Z","shell.execute_reply":"2024-08-11T09:50:42.899167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Build the improved model\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(64, return_sequences=False, kernel_regularizer='l2', recurrent_dropout=0.3), input_shape=(X_train.shape[1], X_train.shape[2])))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, kernel_regularizer='l2'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu', kernel_regularizer='l2'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n\n# Early stopping callback\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Learning rate reduction callback\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n\n# Train the model with early stopping and validation\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T11:52:31.830217Z","iopub.execute_input":"2024-08-11T11:52:31.830929Z","iopub.status.idle":"2024-08-11T12:10:32.640313Z","shell.execute_reply.started":"2024-08-11T11:52:31.830886Z","shell.execute_reply":"2024-08-11T12:10:32.639377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Predict on test data\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n\n# Calculate precision and recall\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:11:24.053833Z","iopub.execute_input":"2024-08-11T12:11:24.054683Z","iopub.status.idle":"2024-08-11T12:12:00.892018Z","shell.execute_reply.started":"2024-08-11T12:11:24.054651Z","shell.execute_reply":"2024-08-11T12:12:00.891091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on test data with adjusted threshold\nthresholds = np.arange(0.1, 0.9, 0.05)\nbest_precision = 0\nbest_recall = 0\nbest_threshold = 0.5\n\nfor threshold in thresholds:\n    y_pred = (model.predict(X_test) > threshold).astype(\"int32\")\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    \n    # Find the best threshold balancing precision and recall\n    if precision > best_precision and recall > best_recall:\n        best_precision = precision\n        best_recall = recall\n        best_threshold = threshold\n\nprint(f'Best Precision: {best_precision}')\nprint(f'Best Recall: {best_recall}')\nprint(f'Best Threshold: {best_threshold}')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:12:36.629624Z","iopub.execute_input":"2024-08-11T12:12:36.630262Z","iopub.status.idle":"2024-08-11T12:22:14.732746Z","shell.execute_reply.started":"2024-08-11T12:12:36.630231Z","shell.execute_reply":"2024-08-11T12:22:14.731808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Previous\nmetrics_new = [\n    keras.metrics.Precision(name=\"precision\"),\n    keras.metrics.Recall(name=\"recall\"),\n]\n\nwindow_size = 20\nlearning_rate = 0.0001\noptimizer = Adam(learning_rate=learning_rate)\n\nmodel1 = Sequential()\nmodel1.add(Input(shape=(window_size, X_train.shape[2])))\nmodel1.add(LSTM(units = 128, activation='tanh',return_sequences= True))\nmodel1.add(Dropout(0.2))\nmodel1.add(LSTM(units = 64, activation='tanh',return_sequences= True))\nmodel1.add(Dropout(0.2))\nmodel1.add(LSTM(units = 64, activation='tanh'))\nmodel1.add(Dense(1, activation='sigmoid'))\nmodel1.compile(optimizer=optimizer, loss='BinaryCrossentropy', metrics=metrics_new)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Learning rate reduction callback\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n\n# Train the model\nhistory = model1.fit(X_train, y_train,epochs=32,batch_size=64,validation_split=0.3,callbacks=[early_stopping],verbose=1)\n# model1.summary()\n# model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:38:11.640196Z","iopub.execute_input":"2024-08-11T12:38:11.640559Z","iopub.status.idle":"2024-08-11T12:39:05.097836Z","shell.execute_reply.started":"2024-08-11T12:38:11.640529Z","shell.execute_reply":"2024-08-11T12:39:05.097052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n\n# Calculate precision and recall\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:40:31.65465Z","iopub.execute_input":"2024-08-11T12:40:31.655004Z","iopub.status.idle":"2024-08-11T12:41:07.947836Z","shell.execute_reply.started":"2024-08-11T12:40:31.654977Z","shell.execute_reply":"2024-08-11T12:41:07.946864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:41:20.670429Z","iopub.execute_input":"2024-08-11T12:41:20.671102Z","iopub.status.idle":"2024-08-11T12:41:20.926037Z","shell.execute_reply.started":"2024-08-11T12:41:20.671072Z","shell.execute_reply":"2024-08-11T12:41:20.925154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmetrics_new = [\n    keras.metrics.Precision(name=\"precision\"),\n    keras.metrics.Recall(name=\"recall\"),\n]\n\nwindow_size = 20\nlearning_rate = 0.0001\noptimizer = Adam(learning_rate=learning_rate)\n\nmodel1 = Sequential()\nmodel1.add(Input(shape=(window_size, X_train.shape[2])))\nmodel1.add(LSTM(units=128, activation='tanh', return_sequences=True, kernel_regularizer=l2(0.001)))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\nmodel1.add(LSTM(units=64, activation='tanh', return_sequences=True, kernel_regularizer=l2(0.001)))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\nmodel1.add(LSTM(units=64, activation='tanh', kernel_regularizer=l2(0.001)))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.3))\nmodel1.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001)))\nmodel1.compile(optimizer=optimizer, loss='BinaryCrossentropy', metrics=metrics_new)\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\n# Learning rate reduction callback\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.00001, verbose=1)\n\n# Train the model\nhistory = model1.fit(X_train, y_train, epochs=32, batch_size=64, validation_split=0.3, callbacks=[early_stopping, reduce_lr], verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:44:42.058772Z","iopub.execute_input":"2024-08-11T12:44:42.059576Z","iopub.status.idle":"2024-08-11T12:45:39.773916Z","shell.execute_reply.started":"2024-08-11T12:44:42.059547Z","shell.execute_reply":"2024-08-11T12:45:39.773128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## FastAI","metadata":{}},{"cell_type":"code","source":"!pip install -q fastai --upgrade\nfrom fastai.tabular.all import *\nfrom fastai.callback.all import *","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:48:14.409397Z","iopub.execute_input":"2024-08-11T12:48:14.409765Z","iopub.status.idle":"2024-08-11T12:48:34.008058Z","shell.execute_reply.started":"2024-08-11T12:48:14.409735Z","shell.execute_reply":"2024-08-11T12:48:34.007059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:50:31.715996Z","iopub.execute_input":"2024-08-11T12:50:31.716354Z","iopub.status.idle":"2024-08-11T12:50:31.720814Z","shell.execute_reply.started":"2024-08-11T12:50:31.716326Z","shell.execute_reply":"2024-08-11T12:50:31.719723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert data to torch tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.float32)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:48:44.948837Z","iopub.execute_input":"2024-08-11T12:48:44.950564Z","iopub.status.idle":"2024-08-11T12:48:45.083448Z","shell.execute_reply.started":"2024-08-11T12:48:44.950517Z","shell.execute_reply":"2024-08-11T12:48:45.082525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine tensors into a Dataset\ntrain_ds = TensorDataset(X_train_tensor, y_train_tensor)\nvalid_ds = TensorDataset(X_test_tensor, y_test_tensor)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:50:36.062386Z","iopub.execute_input":"2024-08-11T12:50:36.062754Z","iopub.status.idle":"2024-08-11T12:50:36.06833Z","shell.execute_reply.started":"2024-08-11T12:50:36.062726Z","shell.execute_reply":"2024-08-11T12:50:36.067431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create DataLoaders\ntrain_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=64, shuffle=False)\n\ndls = DataLoaders(train_dl, valid_dl)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:50:42.401531Z","iopub.execute_input":"2024-08-11T12:50:42.401896Z","iopub.status.idle":"2024-08-11T12:50:42.40746Z","shell.execute_reply.started":"2024-08-11T12:50:42.401868Z","shell.execute_reply":"2024-08-11T12:50:42.406395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the LSTM model using fastai's Learner\nclass LSTMModel(Module):\n    def __init__(self):\n        self.lstm1 = nn.LSTM(input_size=X_train.shape[2], hidden_size=128, batch_first=True)\n        self.lstm2 = nn.LSTM(input_size=128, hidden_size=64, batch_first=True)\n        self.drop = nn.Dropout(0.3)\n        self.fc = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x, (h, c) = self.lstm1(x)\n        x, (h, c) = self.lstm2(x)\n        x = self.drop(x[:, -1, :])  # Get the last time step\n        x = self.fc(x)\n        return torch.sigmoid(x)\n\n# Instantiate the model\nmodel = LSTMModel()\n\n# Define loss function and optimizer\nloss_func = BCEWithLogitsLossFlat()\nopt_func = Adam\n\n# Define metrics\nmetrics = [Precision(), Recall()]\n\n# Create a Learner\nlearn = Learner(dls, model, loss_func=loss_func, opt_func=opt_func, metrics=metrics, cbs=[EarlyStoppingCallback(monitor='valid_loss', patience=3), ReduceLROnPlateau()])\n\n# Train the model\nlearn.fit_one_cycle(32, lr_max=1e-3)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T12:53:56.258877Z","iopub.execute_input":"2024-08-11T12:53:56.259851Z","iopub.status.idle":"2024-08-11T12:55:09.93195Z","shell.execute_reply.started":"2024-08-11T12:53:56.259812Z","shell.execute_reply":"2024-08-11T12:55:09.930956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_new = model1.predict(X_test)\ncheck_value = 0.2\npredictions_01 = (predictions_new > check_value).astype(int)\ny_new_binary = (y_test > check_value).astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-08-11T13:38:42.266585Z","iopub.execute_input":"2024-08-11T13:38:42.26703Z","iopub.status.idle":"2024-08-11T13:38:53.614837Z","shell.execute_reply.started":"2024-08-11T13:38:42.266997Z","shell.execute_reply":"2024-08-11T13:38:53.613814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n\nprecision = precision_score(y_new_binary, predictions_01, average='macro')\nrecall = recall_score(y_new_binary, predictions_01, average='macro')\nf1 = f1_score(y_new_binary, predictions_01, average='macro')\nconf_matrix = confusion_matrix(y_new_binary, predictions_01)\n\nprint(f'Precision: {precision}')\nprint(f'Recall: {recall}')\nprint(f'F1 Score: {f1}')\nprint(f'Confusion Matrix:\\n{conf_matrix}')","metadata":{"execution":{"iopub.status.busy":"2024-08-11T13:38:56.331679Z","iopub.execute_input":"2024-08-11T13:38:56.332052Z","iopub.status.idle":"2024-08-11T13:38:56.472572Z","shell.execute_reply.started":"2024-08-11T13:38:56.332021Z","shell.execute_reply":"2024-08-11T13:38:56.471382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}